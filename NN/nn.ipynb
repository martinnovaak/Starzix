{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b7e3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_gpu():\n",
    "    import tensorflow as tf\n",
    "    print(\"tf.test.is_built_with_cuda()\")\n",
    "    print(tf.test.is_built_with_cuda())\n",
    "    \n",
    "    print()\n",
    "    print(\"tf.config.list_physical_devices('GPU')\")\n",
    "    print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "    print()\n",
    "    print(\"tf.config.experimental.list_physical_devices('GPU')\")\n",
    "    print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "#check_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d67b374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generateData():    \n",
    "    chess_evals = pd.read_csv(\"chessData.csv\")\n",
    "    random_evals = pd.read_csv(\"random_evals.csv\")\n",
    "    tactic_evals = pd.read_csv(\"tactic_evals.csv\")\n",
    "    df = pd.concat([chess_evals, random_evals, tactic_evals], join=\"inner\")\n",
    "    df = df.drop_duplicates(subset=df.columns[0]) # remove repeated rows\n",
    "    df = df.sample(frac=1, random_state=3)  # frac=1 shuffles all rows\n",
    "    \n",
    "    trainFile = open(\"train.csv\", \"w\")\n",
    "    testFile = open(\"test.csv\", \"w\")\n",
    "    trainFile.write(\"FEN,Evaluation\\n\")    \n",
    "    testFile.write(\"FEN,Evaluation\\n\") \n",
    "        \n",
    "    def clamp(x):\n",
    "        if x <= -1000:\n",
    "            return -1000\n",
    "        if x >= 1000:\n",
    "            return 1000\n",
    "        return x\n",
    "    \n",
    "    from stockfish import Stockfish\n",
    "    parameters = {\"Threads\": 4, \"Hash\": 1024}\n",
    "    stockfish = Stockfish(path=\"/users/ricar/desktop/stockfish/stockfish-windows-x86-64-avx2.exe\", depth=9, parameters=parameters)\n",
    "    \n",
    "    i = 0\n",
    "    for fen in df[\"FEN\"].values:\n",
    "        stockfish.set_fen_position(fen)\n",
    "        eval = stockfish.get_evaluation()\n",
    "        if eval[\"type\"] != \"cp\":\n",
    "            continue\n",
    "        value = clamp(int(eval[\"value\"]))\n",
    "        i += 1\n",
    "        if i % 5 == 0:\n",
    "            testFile.write(fen + \",\" + str(value) + \"\\n\")\n",
    "        else:\n",
    "            trainFile.write(fen + \",\" + str(value) + \"\\n\")\n",
    "        if i % 100 == 0:\n",
    "            print(i, \"evaluated\" end=\"\\r\")\n",
    "        \n",
    "generateData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa283312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pandas as pd\n",
    "\n",
    "def countLines(filename):\n",
    "    with open(filename, \"r\") as file:\n",
    "        line_count = sum(1 for line in file)\n",
    "    return line_count\n",
    "\n",
    "numTrainExamples = countLines(\"train.csv\") - 1\n",
    "numTestExamples = countLines(\"test.csv\") - 1\n",
    "ratio = numTestExamples / (numTrainExamples + numTestExamples)\n",
    "print(\"numTrainExamples\", numTrainExamples)\n",
    "print(\"numTestExamples\", numTestExamples)\n",
    "print(\"test \" + str(round(ratio,2) * 100) + \"%\")\n",
    "\n",
    "def loadData(file, idx, batch_size):\n",
    "    df = pd.read_csv(file, skiprows=idx*batch_size, nrows=batch_size)\n",
    "    x = [fen_to_12_8x8(fen) for fen in df[df.columns[0]].tolist()]\n",
    "    y = df[df.columns[1]].tolist()\n",
    "    return (np.array(x), np.array(y))\n",
    "\n",
    "def batchGenerator(file, batch_size, steps):\n",
    "    idx=1\n",
    "    while True: \n",
    "        yield loadData(file, idx-1, batch_size) # Yields data\n",
    "        if idx<steps:\n",
    "            idx+=1\n",
    "        else:\n",
    "            idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9c808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chess\n",
    "\n",
    "def fen_to_12_8x8(myFen, flip=True):\n",
    "    whiteToMove = \" w \" in myFen\n",
    "    if not flip or whiteToMove:\n",
    "        board = chess.Board(myFen)\n",
    "    elif flip and not whiteToMove:\n",
    "        splitted = myFen.split(\" \")\n",
    "        splitted[0] = splitted[0].swapcase() # Flip piece colors\n",
    "        # Now we have to invert the rows\n",
    "        rows = splitted[0].split(\"/\")\n",
    "        leftPartReversed = \"\"\n",
    "        for i in range(len(rows)-1, -1, -1): # start stop step\n",
    "            leftPartReversed += rows[i]\n",
    "            if i != 0:\n",
    "                leftPartReversed += \"/\"\n",
    "        splitted[0] = leftPartReversed\n",
    "        fen = \" \".join(splitted)\n",
    "        board = chess.Board(fen)\n",
    "    \n",
    "    pieces = [chess.PAWN, chess.KNIGHT, chess.BISHOP, chess.ROOK, chess.QUEEN, chess.KING]\n",
    "    array = np.empty((12,8,8), dtype=int)\n",
    "    i = 0 \n",
    "    for color in [chess.WHITE, chess.BLACK]:\n",
    "        for piece in pieces:\n",
    "            bitboard = np.asarray(board.pieces(piece, color).tolist()).astype(int)\n",
    "            bitboard = bitboard.reshape(8,8)\n",
    "            array[i] = bitboard\n",
    "            i += 1\n",
    "            \n",
    "    return array\n",
    "\n",
    "# rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
    "#fen_to_12_8x8(\"7k/7p/6p1/4pp2/4P3/8/3Q1PPP/7K w - - 0 1\")\n",
    "#print()\n",
    "#fen_to_12_8x8(\"7k/7p/6p1/4pp2/4P3/8/3Q1PPP/7K b - - 0 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad6ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def train():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(name=\"flatten\", input_shape=(12, 8, 8)))  # Flatten the 3D input to a 1D array\n",
    "    model.add(Dense(name=\"dense32\", units=32, activation='relu'))\n",
    "    model.add(Dense(name=\"dense1\", units=1, activation='linear'))\n",
    "    model.compile(loss=\"mae\", optimizer=Adam(learning_rate=0.001)) # default lr 0.001\n",
    "    model.summary()\n",
    "\n",
    "    batch_size = 16\n",
    "    epochs = 30\n",
    "    steps_per_epoch = np.ceil(numTrainExamples/batch_size)\n",
    "    validation_steps = np.ceil(numTestExamples/batch_size)\n",
    "    my_training_batch_generator = batchGenerator('train.csv', batch_size, steps_per_epoch)\n",
    "    my_validation_batch_generator = batchGenerator('test.csv', batch_size, validation_steps)\n",
    "\n",
    "    history = model.fit(my_training_batch_generator,\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        validation_data=my_validation_batch_generator,\n",
    "                        validation_steps=validation_steps)\n",
    "    \n",
    "    model.save(\"model.h5\")\n",
    "    with open(\"history\", 'wb') as hist:\n",
    "        pickle.dump(history.history, hist) \n",
    "    \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cb5b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "    \n",
    "model = load_model(\"model.h5\")\n",
    "with open(\"history\", \"rb\") as hist_file:\n",
    "    history = pickle.load(hist_file)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6f6984",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating on test set...\")\n",
    "loss = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdb404",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot():\n",
    "    import matplotlib.pyplot as plt\n",
    "    global history\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "    # Plot training and validation loss over epochs\n",
    "    plt.plot(history['loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss (RMSE)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98075fa3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def printWeightsForCpp(model):\n",
    "    for layer in model.layers:\n",
    "        print(\"------ LAYER\", layer.name, \"------\")\n",
    "        weights = layer.get_weights()\n",
    "        if len(weights) > 0:\n",
    "            rows, cols = weights[0].shape\n",
    "            if cols > 1:\n",
    "                print(f\"double {layer.name}[{rows}][{cols}] = {{\", end=\"\")\n",
    "                for row in weights[0]:\n",
    "                    print(\"{\", \",\".join(str(val) for val in row), \"},\", end=\"\")\n",
    "            else:\n",
    "                print(f\"double {layer.name}[{rows}] = {{\", end=\"\")\n",
    "                for row in weights[0]:\n",
    "                    print(\",\".join(str(val) for val in row), \",\", end=\"\")\n",
    "\n",
    "            print(\"};\")\n",
    "            print()\n",
    "        print()\n",
    "        \n",
    "printWeightsForCpp(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc4ea9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def printBiasesForCpp(model):\n",
    "    for layer in model.layers:\n",
    "        print(\"------ LAYER\", layer.name, \"------\")\n",
    "        biases = layer.get_weights()[1]\n",
    "        print(f\"double biases[{len(biases)}] = {{\", end=\"\")\n",
    "        print(\",\".join(str(val) for val in biases), \",\")\n",
    "        print()\n",
    "        \n",
    "printBiasesForCpp(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba71e66d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input = np.array([i % 4 for i in range(769)])\n",
    "input = input.reshape(1, 769)\n",
    "\n",
    "predictions = model.predict(input)\n",
    "print(\"Prediction:\", predictions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a98b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
