{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataIntoFiles():\n",
    "    f = open(\"sf_d9.plain\", \"r\")\n",
    "    linesPerFile = 100002\n",
    "    myDir = \"sf_d9_data/\"\n",
    "\n",
    "    linesProcessed = 0\n",
    "    fileNum = 0\n",
    "    currentFileName = myDir + \"sf_d9_0.plain\"\n",
    "    currentFile = open(currentFileName, \"w\")\n",
    "    for line in f:\n",
    "        currentFile.write(line)\n",
    "        linesProcessed += 1\n",
    "        if linesProcessed == linesPerFile:\n",
    "            print(\"Finished file \" + currentFileName)\n",
    "            linesProcessed = 0\n",
    "            fileNum += 1\n",
    "            currentFileName = myDir + \"sf_d9_\" + str(fileNum) + \".plain\"\n",
    "            currentFile = open(currentFileName, \"w\")\n",
    "            \n",
    "#splitDataIntoFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59695592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "fileNames = []\n",
    "for fileName in os.listdir(\"sf_d9_data\"):\n",
    "    fileNames.append(\"sf_d9_data/\" + fileName)\n",
    "numFiles = len(fileNames)\n",
    "print(\"Files:\", numFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ff116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def getFensAndScores(fileName):\n",
    "    f = open(fileName, \"r\")\n",
    "    lines = f.readlines()\n",
    "    leng = len(lines)\n",
    "    i = 0\n",
    "    fens = []\n",
    "    scores = []\n",
    "    while i < leng and i+2 < leng:\n",
    "        lines[i] = lines[i].strip() # lines[i] is \"fen <fen>\"\n",
    "        lines[i+2] = lines[i+2].strip() # lines[i+2] is \"score -529\"\n",
    "\n",
    "        fen = lines[i][4:] # lines[i] is \"fen <fen>\"\n",
    "\n",
    "        score = int(lines[i+2][6:]) # lines[i+2] is \"score -529\"\n",
    "        if score > 750:\n",
    "            score = 750\n",
    "        elif score < -750:\n",
    "            score = -750\n",
    "        if \" b \" in fen:\n",
    "            score = -score # scores in the file are stm, mirror black ones to get white perspective\n",
    "\n",
    "        fens.append(fen)\n",
    "        scores.append(score)\n",
    "        i += random.randint(10, 20) * 6 # jump to next random fen (\"fen <fen>\" line is every 6 lines)\n",
    "    return fens, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ae61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fens = []\n",
    "scores = []\n",
    "for fileName in fileNames[:250]:\n",
    "    thisFens, thisScores = getFensAndScores(fileName)\n",
    "    fens += thisFens\n",
    "    scores += thisScores\n",
    "\n",
    "print(\"Positions:\", len(fens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9c808a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chess\n",
    "\n",
    "def fen_to_12x64(fen, debug=False):\n",
    "    board = chess.Board(fen)\n",
    "        \n",
    "    pieces = [chess.PAWN, chess.KNIGHT, chess.BISHOP, chess.ROOK, chess.QUEEN, chess.KING]\n",
    "    res = np.zeros((12, 64))\n",
    "    i = 0 \n",
    "    for color in [chess.WHITE, chess.BLACK]:\n",
    "        for piece in pieces:\n",
    "            bitboard = board.pieces(piece, color).tolist()\n",
    "            bitboard = np.asarray(bitboard).astype(int)\n",
    "            if debug:\n",
    "                print(piece, \"white\" if color == chess.WHITE else \"black\")\n",
    "                print(bitboard.reshape((8,8)))\n",
    "            res[i] = bitboard\n",
    "            i += 1\n",
    "            \n",
    "    return res\n",
    "\n",
    "def fen_to_769(fen):\n",
    "    bbs = fen_to_12x64(fen)\n",
    "    _768 = bbs.reshape(768, 1)\n",
    "    _769 = np.append(_768, 1 if \" b \" in fen else 0)\n",
    "    return _769\n",
    "\n",
    "# rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
    "#fen_to_12x64(\"7k/7p/6p1/4pp2/4P3/8/3Q1PPP/7K w - - 0 1\", debug=True)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad6ae7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train = [fen_to_769(fen) for fen in fens]\n",
    "del fens\n",
    "print(\"Finished parsing fens to bbs\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X_train), np.array(scores), test_size=0.1, random_state=3)\n",
    "del scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf85b49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# mean(abs(tanh(output/400) - tanh(cp/400)))\n",
    "def custom_loss(y_true, y_pred):\n",
    "    from tensorflow import reduce_mean, tanh, cast, float32, abs, reduce_sum\n",
    "    y_true = cast(y_true, dtype=float32)  # Convert y_true to float32\n",
    "    y_pred = cast(y_pred, dtype=float32)  # Convert y_pred to float32\n",
    "    tanh_output = tanh(y_pred / 400)\n",
    "    tanh_cp = tanh(y_true / 400)\n",
    "    abs_diff = abs(tanh_output - tanh_cp)\n",
    "    loss = reduce_mean(abs_diff)\n",
    "    return loss\n",
    "\n",
    "def train():\n",
    "    from tensorflow.keras.layers import Dense, Flatten\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "    model = Sequential()\n",
    "    #model.add(Flatten(name=\"flatten\", input_shape=(12, 64)))  # Flatten the 3D input to a 1D array\n",
    "    model.add(Dense(name=\"dense32\", units=32, activation='relu', input_dim=769))\n",
    "    model.add(Dense(name=\"output\", units=1, activation='linear'))\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss=custom_loss, optimizer=Adam(learning_rate=0.01)) # default lr 0.001\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2,\n",
    "                       callbacks=[EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)])\n",
    "    \n",
    "    model.save(\"model.h5\")\n",
    "    with open(\"history\", 'wb') as hist:\n",
    "        pickle.dump(history.history, hist) \n",
    "    \n",
    "#train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cb5b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "    \n",
    "model = load_model(\"model.h5\", custom_objects={'custom_loss': custom_loss})\n",
    "with open(\"history\", \"rb\") as hist_file:\n",
    "    history = pickle.load(hist_file)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdb404",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "    # Plot training and validation loss over epochs\n",
    "    plt.plot(history['loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d41942",
   "metadata": {},
   "outputs": [],
   "source": [
    "_769 = fen_to_769(\"rnbk1bnr/pp3Bpp/2p5/4p3/4P3/8/PPP2PPP/RNB1K1NR b KQ - 0 6\").reshape(1,769,1)\n",
    "print(model.predict(_769)[0][0])\n",
    "_769 = fen_to_769(\"rnbk1bnr/pp3Bpp/2p5/4p3/4P3/8/PPP2PPP/RNB1K1NR w KQ - 0 6\").reshape(1,769,1)\n",
    "print(model.predict(_769)[0][0])\n",
    "_769 = fen_to_769(\"rnb5/pp1nkr1p/2p5/4pp2/4P3/8/PPP1N1PP/RN3RK1 w - - 2 13\").reshape(1,769,1)\n",
    "print(model.predict(_769)[0][0]) # -4.9\n",
    "_769 = fen_to_769(\"rnb5/pp1nkr1p/2p5/4pp2/4P3/8/PPP1N1PP/RN3RK1 b - - 2 13\").reshape(1,769,1)\n",
    "print(model.predict(_769)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d40b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(X_test, y_test)\n",
    "#model.evaluate(X_test, y_test, batch_size=64)\n",
    "\n",
    "def calculateCpLoss(testBbs, testScores):\n",
    "    totalLoss = 0.0\n",
    "    i = 0\n",
    "    for bbs in testBbs:\n",
    "        bbs = bbs.reshape(1,769,1)\n",
    "        pred = model.predict(bbs, verbose=0)[0][0]\n",
    "        totalLoss += abs(pred - testScores[i])\n",
    "        i += 1\n",
    "    return totalLoss / len(testBbs)\n",
    "\n",
    "fens, scores = getFensAndScores(\"sf_d9_data/sf_d9_1000.plain\")\n",
    "X_white, X_black, whiteScores, blackScores = [], [], [], []\n",
    "i = -1\n",
    "while True:\n",
    "    i += 1\n",
    "    if \" w \" in fens[i] and len(X_white) < 500:\n",
    "        X_white.append(fen_to_769(fens[i]))\n",
    "        whiteScores.append(scores[i])\n",
    "    elif \" b \" in fens[i] and len(X_black) < 500:\n",
    "        X_black.append(fen_to_769(fens[i]))\n",
    "        blackScores.append(scores[i])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"White centipawn loss:\", calculateCpLoss(X_white, whiteScores))\n",
    "print(\"Black centipawn loss:\", calculateCpLoss(X_black, blackScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98075fa3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def printWeightsForCpp(model):\n",
    "    for layer in model.layers:\n",
    "        print(\"------ LAYER\", layer.name, \"------\")\n",
    "        weights = layer.get_weights()\n",
    "        if len(weights) > 0:\n",
    "            rows, cols = weights[0].shape\n",
    "            if cols > 1:\n",
    "                print(f\"double {layer.name}[{rows}][{cols}] = {{\", end=\"\")\n",
    "                for row in weights[0]:\n",
    "                    print(\"{\", \",\".join(str(val) for val in row), \"},\", end=\"\")\n",
    "            else:\n",
    "                print(f\"double {layer.name}[{rows}] = {{\", end=\"\")\n",
    "                for row in weights[0]:\n",
    "                    print(\",\".join(str(val) for val in row), \",\", end=\"\")\n",
    "\n",
    "            print(\"};\")\n",
    "            print()\n",
    "        print()\n",
    "        \n",
    "printWeightsForCpp(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc4ea9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def printBiasesForCpp(model):\n",
    "    for layer in model.layers:\n",
    "        print(\"------ LAYER\", layer.name, \"------\")\n",
    "        biases = layer.get_weights()[1]\n",
    "        print(f\"double biases[{len(biases)}] = {{\", end=\"\")\n",
    "        print(\",\".join(str(val) for val in biases), \",\")\n",
    "        print()\n",
    "        \n",
    "printBiasesForCpp(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a98b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
