{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3b7e3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def check_gpu():\n",
    "    import tensorflow as tf\n",
    "    print(\"tf.test.is_built_with_cuda()\")\n",
    "    print(tf.test.is_built_with_cuda())\n",
    "    \n",
    "    print()\n",
    "    print(\"tf.config.list_physical_devices('GPU')\")\n",
    "    print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "    print()\n",
    "    print(\"tf.config.experimental.list_physical_devices('GPU')\")\n",
    "    print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "#check_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bcd13d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26744, 2)\n",
      "Avg eval: -7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chess_evals = pd.read_csv(\"chessData.csv\").head(10000)\n",
    "random_evals = pd.read_csv(\"random_evals.csv\").head(10000)\n",
    "tactic_evals = pd.read_csv(\"tactic_evals.csv\").head(10000)\n",
    "df = pd.concat([chess_evals, random_evals, tactic_evals], join=\"inner\")\n",
    "df = df.sample(frac=1, random_state=42)  # frac=1 shuffles all rows\n",
    "\n",
    "def isEvaluationNumeric(myStr):\n",
    "    try:\n",
    "        myStr = myStr.lstrip('-')\n",
    "        x = int(myStr)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Convert the Evaluation column to integers and remove rows where conversion is not possible\n",
    "df = df[df['Evaluation'].apply(lambda x: isEvaluationNumeric(x))]\n",
    "df['Evaluation'] = df['Evaluation'].astype(int)\n",
    "\n",
    "# Invert black evals\n",
    "#df['Evaluation'] = df.apply(lambda row: -row['Evaluation'] if ' b ' in row['FEN'] else row['Evaluation'], axis=1)\n",
    "\n",
    "def clamp(x):\n",
    "    if x <= -1000:\n",
    "        return -1000\n",
    "    if x >= 1000:\n",
    "        return 1000\n",
    "    return x\n",
    "# Clamp\n",
    "df['Evaluation'] = df.apply(lambda row: clamp(row[\"Evaluation\"]), axis=1)\n",
    "\n",
    "def normalize(number, min_range, max_range):\n",
    "    scaled_value = -1 + 2 * (number - min_range) / (max_range - min_range)\n",
    "    return scaled_value\n",
    "# Normalize to between -1 and 1\n",
    "#df['Evaluation'] = df.apply(lambda row: normalize(row[\"Evaluation\"], -10, 10), axis=1)\n",
    "\n",
    "print(df.shape)\n",
    "print(\"Avg eval:\", round(df[\"Evaluation\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d67b374",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'cp', 'value': 43}\n"
     ]
    }
   ],
   "source": [
    "def generateData():\n",
    "    from stockfish import Stockfish\n",
    "    f = open(\"data.csv\", \"w\")\n",
    "    f.write(\"FEN,Evaluation\")        \n",
    "    stockfish = Stockfish(path=\"/users/ricar/desktop/stockfish/stockfish-windows-x86-64-avx2.exe\",\n",
    "                          depth=9, \n",
    "                          parameters={\"Threads\": 4})\n",
    "    i = 0\n",
    "    for fen in df[\"FEN\"].values:\n",
    "        eval = stockfish.get_evaluation()\n",
    "        if eval[\"type\"] != \"cp\":\n",
    "            continue\n",
    "        value = clamp(int(eval[\"value\"]))\n",
    "        f.write(fen + \",\" + str(value))\n",
    "        print(str(i+1) + \" evaluated\")\n",
    "        \n",
    "generateData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc8dc6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chess\n",
    "\n",
    "def fen_to_12_8x8(myFen):\n",
    "    whiteToMove = \" w \" in myFen\n",
    "    if whiteToMove:\n",
    "        board = chess.Board(myFen)\n",
    "    else:\n",
    "        splitted = myFen.split(\" \")\n",
    "        splitted[0] = splitted[0].swapcase() # Flip piece colors\n",
    "        # Now we have to invert the rows\n",
    "        rows = splitted[0].split(\"/\")\n",
    "        leftPartReversed = \"\"\n",
    "        for i in range(len(rows)-1, -1, -1): # start stop step\n",
    "            leftPartReversed += rows[i]\n",
    "            if i != 0:\n",
    "                leftPartReversed += \"/\"\n",
    "        splitted[0] = leftPartReversed\n",
    "        fen = \" \".join(splitted)\n",
    "        board = chess.Board(fen)\n",
    "    \n",
    "    pieces = [chess.PAWN, chess.KNIGHT, chess.BISHOP, chess.ROOK, chess.QUEEN, chess.KING]\n",
    "    array = np.empty((12,8,8), dtype=int)\n",
    "    i = 0 \n",
    "    for color in [chess.WHITE, chess.BLACK]:\n",
    "        for piece in pieces:\n",
    "            bitboard = np.asarray(board.pieces(piece, color).tolist()).astype(int)\n",
    "            bitboard = bitboard.reshape(8,8)\n",
    "            array[i] = bitboard\n",
    "            i += 1\n",
    "            \n",
    "    return array\n",
    "\n",
    "# rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
    "#fen_to_12_8x8(\"7k/7p/6p1/4pp2/4P3/8/3Q1PPP/7K w - - 0 1\")\n",
    "#print()\n",
    "#fen_to_12_8x8(\"7k/7p/6p1/4pp2/4P3/8/3Q1PPP/7K b - - 0 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e8c31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "X = np.array([fen_to_12_8x8(fen) for fen in df['FEN'].values])\n",
    "y = df['Evaluation'].values\n",
    "del df\n",
    "y = y.reshape(y.shape[0],1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71b625",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def train():\n",
    "    from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
    "    from tensorflow.keras.models import Model, Sequential\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "    \n",
    "    #model = Sequential()\n",
    "    #model.add(Dense(units=32, activation='relu', input_dim=769))\n",
    "    #model.add(Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(12, 8, 8)))  # Flatten the 3D input to a 1D array\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.summary()\n",
    "        \n",
    "    model.compile(loss=\"mae\", optimizer=Adam(learning_rate=0.01)) # default lr 0.001\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    model.save(\"model.h5\")\n",
    "    with open(\"history\", 'wb') as hist:\n",
    "        pickle.dump(history.history, hist) \n",
    "    \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cb5b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "    \n",
    "model = load_model(\"model.h5\")\n",
    "with open(\"history\", \"rb\") as hist_file:\n",
    "    history = pickle.load(hist_file)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6f6984",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating on test set...\")\n",
    "loss = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdb404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot():\n",
    "    import matplotlib.pyplot as plt\n",
    "    global history\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "    # Plot training and validation loss over epochs\n",
    "    plt.plot(history['loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss (RMSE)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98075fa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def printWeightsForCpp(model):\n",
    "    for layer in model.layers:\n",
    "        print(\"------ LAYER\", layer.name, \"------\")\n",
    "        weights = layer.get_weights()\n",
    "        if len(weights) > 0:\n",
    "            rows, cols = weights[0].shape\n",
    "            if cols > 1:\n",
    "                print(f\"double {layer.name}[{rows}][{cols}] = {{\", end=\"\")\n",
    "                for row in weights[0]:\n",
    "                    print(\"{\", \",\".join(str(val) for val in row), \"},\", end=\"\")\n",
    "            else:\n",
    "                print(f\"double {layer.name}[{rows}] = {{\", end=\"\")\n",
    "                for row in weights[0]:\n",
    "                    print(\",\".join(str(val) for val in row), \",\", end=\"\")\n",
    "\n",
    "            print(\"};\")\n",
    "            print()\n",
    "        print()\n",
    "        \n",
    "printWeightsForCpp(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc4ea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def printBiasesForCpp(model):\n",
    "    for layer in model.layers:\n",
    "        print(\"------ LAYER\", layer.name, \"------\")\n",
    "        biases = layer.get_weights()[1]\n",
    "        print(f\"double biases[{len(biases)}] = {{\", end=\"\")\n",
    "        print(\",\".join(str(val) for val in biases), \",\")\n",
    "        print()\n",
    "        \n",
    "printBiasesForCpp(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba71e66d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input = np.array([i % 4 for i in range(769)])\n",
    "input = input.reshape(1, 769)\n",
    "\n",
    "predictions = model.predict(input)\n",
    "print(\"Prediction:\", predictions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a98b7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
